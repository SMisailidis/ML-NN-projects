# -*- coding: utf-8 -*-
"""Απαλλακτική Εργασία Μηχανική Μάθηση

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a3iTJNd_Be_-tTwPHcJF941i4Eh1hB_r

classes: edible=e, poisonous=p
    cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s
    cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s
    cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y
    bruises: bruises=t,no=f
    odor: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s
    gill-attachment: attached=a,descending=d,free=f,notched=n
    gill-spacing: close=c,crowded=w,distant=d
    gill-size: broad=b,narrow=n
    gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y
    stalk-shape: enlarging=e,tapering=t
    stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?
    stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s
    stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s
    stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y
    stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y
    veil-type: partial=p,universal=u
    veil-color: brown=n,orange=o,white=w,yellow=y
    ring-number: none=n,one=o,two=t
    ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z
    spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y
    population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y
    habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d
"""

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import classification_report
from sklearn.preprocessing import OrdinalEncoder
import seaborn as sns
import plotly.graph_objects as go
from xgboost import XGBClassifier

from sklearn import svm
import plotly.figure_factory as ff
import warnings
from sklearn.model_selection import train_test_split
import numpy as np
import plotly.express as px
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import classification_report
import plotly.graph_objects as go

from google.colab import drive

drive.mount("/content/drive")

path = "/content/drive/MyDrive/Machine Learning/mushrooms.csv"
df = pd.read_csv(path)

df.head()

df.isna().sum()

df.info()
df.replace('?', pd.NA, inplace=True)
df.dropna(inplace=True)

df.isna().sum().sum()

labels = ['Edible', 'Poisonous']
values = [df.describe()['class']['freq'], df.describe()['class']['count']-df.describe()['class']['freq']]
colors = ['green', 'red']

fig = go.Figure(data=[go.Pie(labels=labels, values=values, opacity=0.8)])
fig.update_traces(textinfo='percent+label', marker=dict(line=dict(color='#000000', width=2), colors=colors))
fig.update_layout(title_text='Distribution of the Mushrooms by their Classes', title_x=0.5, title_font=dict(size=20), width=600, height=400)
fig.show()

labels = ['Edible', 'Poisonous']
values = [df.describe()['class']['freq'], df.describe()['class']['count']-df.describe()['class']['freq']]
colors = ['green', 'red']

# Create a bar plot
fig = go.Figure(data=[go.Bar(x=labels, y=values, marker_color=colors, opacity=0.8)])

# Update layout for the bar plot with smaller size
fig.update_layout(
    title_text='Distribution of the Mushrooms by their Classes',
    title_x=0.5,
    title_font=dict(size=20),
    xaxis_title='Class',
    yaxis_title='Count',
    plot_bgcolor='rgba(0,0,0,0)',
    yaxis=dict(showgrid=True, gridcolor='lightgray'),
    width=600,  # Adjust the width
    height=400  # Adjust the height
)

# Show the plot
fig.show()

# Columns to include in the mapping and plotting
features_to_include = [
    'habitat',
    'gill-size',
    'population',
    'cap-color',
    'cap-shape',
    'veil-color',
    'cap-surface',
    'ring-number'
]

# Mapping dictionaries for the selected features
mappings = {
    'cap-shape': {'b': 'bell', 'c': 'conical', 'x': 'convex', 'f': 'flat', 'k': 'knobbed', 's': 'sunken'},
    'cap-surface': {'f': 'fibrous', 'g': 'grooves', 'y': 'scaly', 's': 'smooth'},
    'cap-color': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'r': 'green', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow'},
    'gill-size': {'b': 'broad', 'n': 'narrow'},
    'veil-color': {'n': 'brown', 'o': 'orange', 'w': 'white', 'y': 'yellow'},
    'ring-number': {'n': 'none', 'o': 'one', 't': 'two'},
    'population': {'a': 'abundant', 'c': 'clustered', 'n': 'numerous', 's': 'scattered', 'v': 'several', 'y': 'solitary'},
    'habitat': {'g': 'grasses', 'l': 'leaves', 'm': 'meadows', 'p': 'paths', 'u': 'urban', 'w': 'waste', 'd': 'woods'}
}

tempdf = df.copy()

# Apply the mappings only to the selected columns
for column in features_to_include:
    if column in mappings:
        tempdf[column] = tempdf[column].map(mappings[column])

# Set the target variable
target = 'class'  # 'class' is the target variable (edible = 'e', poisonous = 'p')

# Set up the figure and axes for subplots
n_features = len(features_to_include)
n_rows = (n_features + 2) // 3  # Calculate rows needed (3 plots per row)
fig, axes = plt.subplots(n_rows, 3, figsize=(20, 5 * n_rows))

# Flatten the axes array for easy indexing
axes = axes.flatten()



# Iterate through each selected feature to create a stacked bar plot
for i, column in enumerate(features_to_include):
    # Create a crosstab (pivot table) for the feature and target variable
    crosstab = pd.crosstab(tempdf[column], tempdf[target])

    # Plot a stacked bar plot on the respective subplot
    crosstab.plot(kind='bar', stacked=True, ax=axes[i])

    # Customize the subplot
    axes[i].set_title(f'{column} vs {target}')
    axes[i].set_xlabel(column)
    axes[i].set_ylabel('Count')

# Remove any empty subplots (if any)
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

# Δημιουργία αντικειμένου LabelEncoder
label_encoders = {}
for column in df.columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Υπολογισμός του πίνακα συσχέτισης
correlation_matrix = df.corr()

# Εξετάστε τον πίνακα συσχέτισης
print(correlation_matrix['class'].sort_values(ascending=False))

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Δημιουργία αντικειμένου LabelEncoder και κωδικοποίηση δεδομένων
from sklearn.preprocessing import LabelEncoder
label_encoders = {}
for column in df.columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Υπολογισμός του πίνακα συσχέτισης
correlation_matrix = df.corr()

# Επιλέξτε μόνο τα χαρακτηριστικά που θέλετε να περιλαμβάνονται
features_to_include = [
    'habitat',
    'gill-size',
    'population',
    'cap-color',
    'cap-shape',
    'veil-color',
    'cap-surface',
    'ring-number'
]

# Δημιουργία υποσυνόλου του πίνακα συσχέτισης
subset_correlation_matrix = correlation_matrix.loc[features_to_include, features_to_include]

# Δημιουργία heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(subset_correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', center=0)
plt.show()

print(subset_correlation_matrix.to_string())

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, IterativeImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score, roc_auc_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import time

# Preprocessing: Label Encoding
label_encoder = LabelEncoder()
for column in df.columns:
    df[column] = label_encoder.fit_transform(df[column])

# Split data into features and target
X = df.drop('class', axis=1)
y = df['class']

# Function to check balance of the dataset
def check_balance(y):
    counts = y.value_counts()
    return 'Balanced' if min(counts) / max(counts) > 0.5 else 'Unbalanced'

# Initialize classifiers
classifiers = {
    'AdaBoost': AdaBoostClassifier(),
    'KNN': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'LDA': LinearDiscriminantAnalysis(),
    'MLP Classifier': MLPClassifier(max_iter=500),
    'SVM': SVC(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Logistic Regression': LogisticRegression(),
    'Gradient Boosting': GradientBoostingClassifier(),
}

# Initialize methods for handling missing values
missing_values_methods = ['Bfill', 'Iterative Imputer', 'Linear Regression Imputer', 'Drop Values']

# Initialize results list
results = []

# Iterate over each missing values method
for method_name in missing_values_methods:
    print(f"Applying missing values method: {method_name}")

    if method_name == 'Drop Values':
        X_processed = X.dropna()
        y_processed = y.loc[X_processed.index]
    elif method_name == 'Bfill':
        X_processed = X.fillna(method='bfill')
        y_processed = y
    elif method_name == 'Iterative Imputer':
        imputer = IterativeImputer()
        X_processed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)
        y_processed = y
    elif method_name == 'Linear Regression Imputer':
        # Custom imputation with Linear Regression
        X_processed = X.copy()
        for col in X.columns:
            if X[col].isnull().sum() > 0:
                train_data = X[X[col].notnull()]
                test_data = X[X[col].isnull()]
                lr = LinearRegression()
                lr.fit(train_data.drop(col, axis=1), train_data[col])
                X_processed.loc[test_data.index, col] = lr.predict(test_data.drop(col, axis=1))
        y_processed = y

    balance_status = check_balance(y_processed)

    # 10 repetitions of experiments
    for i in range(10):
        print(f"Experiment {i + 1}/10")

        # Shuffle and split the data
        X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=i)

        # Scale the data
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Define a colormap for confusion matrix visualization
        colors = ["#C4A484", "#FDFD96"]
        cmap_name = "my_custom_map"
        n_bins = 100
        cmap = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)

        for clf_name, clf in classifiers.items():
            print(f"Training {clf_name}...")

            # Record start time
            start_time = time.time()

            # Train the classifier
            clf.fit(X_train_scaled, y_train)

            # Predictions on train and test sets
            y_train_pred = clf.predict(X_train_scaled)
            y_test_pred = clf.predict(X_test_scaled)

            # Record end time
            end_time = time.time()

            for set_name, y_true, y_predictions in [('Train', y_train, y_train_pred), ('Test', y_test, y_test_pred)]:
                # Calculate metrics
                accuracy = accuracy_score(y_true, y_predictions)
                cm = confusion_matrix(y_true, y_predictions)
                f1 = f1_score(y_true, y_predictions)
                recall = recall_score(y_true, y_predictions)
                precision = precision_score(y_true, y_predictions)
                roc_auc = roc_auc_score(y_true, y_predictions)

                # Print metrics
                print(f"Model: {clf_name} ({set_name} Set)")
                print(f"Accuracy: {accuracy:.4f}")
                print(f"F1 Score: {f1:.4f}")
                print(f"Recall: {recall:.4f}")
                print(f"Precision: {precision:.4f}")
                print(f"ROC AUC Score: {roc_auc:.4f}")
                print(f"Confusion Matrix:\n{cm}")

                # Store the results in a dictionary
                result = {
                    'Experiment ID': i + 1,
                    'Missing values method': method_name,
                    'Model': clf_name,
                    'Set': set_name,
                    'Balance': balance_status,
                    'Number of Training Samples': len(X_train),
                    'Accuracy': accuracy,
                    'F1 Score': f1,
                    'Recall': recall,
                    'Precision': precision,
                    'ROC AUC Score': roc_auc,
                    'Execution Time (seconds)': end_time - start_time,
                    'TP': cm[1, 1],
                    'TN': cm[0, 0],
                    'FP': cm[0, 1],
                    'FN': cm[1, 0]
                }
                results.append(result)

                # Visualization (Optional)
                sns.heatmap(cm, annot=True, fmt="d", cmap=cmap, cbar=True, xticklabels=["Edible", "Poisonous"], yticklabels=["Edible", "Poisonous"])
                plt.xlabel("Predicted Labels")
                plt.ylabel("Actual Labels")
                plt.title(f"{clf_name} - {method_name} - {set_name} Set - Experiment {i + 1}")
                plt.show()

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Export to Excel
results_df.to_excel('experiment_results_with_missing_values_methods.xlsx', index=False)

print("Experiments completed and results saved to 'experiment_results_with_missing_values_methods.xlsx'.")